{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto: Lead Tech Estilista Inteligente\n",
        "\n",
        "### Objetivo: Desenvolver um sistema de recomendação de moda utilizando um autoencoder para análise de imagens"
      ],
      "metadata": {
        "id": "6x3efMRk_GpQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBvfPAiYv4D5"
      },
      "outputs": [],
      "source": [
        "!pip install barbar\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7tKO7Jxvhel"
      },
      "outputs": [],
      "source": [
        "# Importação de bibliotecas\n",
        "import zipfile\n",
        "import gc\n",
        "import copy\n",
        "import pickle\n",
        "import time\n",
        "import scipy\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import faiss\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from barbar import Bar\n",
        "from ast import literal_eval\n",
        "from PIL import Image, ImageDraw\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61ymmJAvwNDC"
      },
      "outputs": [],
      "source": [
        "# Função para exibir uma imagem a partir do nome do arquivo\n",
        "def display_image(file_name):\n",
        "    try:\n",
        "        img = Image.open(file_name)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occured: {e}\")\n",
        "\n",
        "# Função para visualizar os itens recomendados com base na imagem selecionada\n",
        "def visualize_nearest_neighbors(selected_img_path, nearest_neighbor_paths):\n",
        "    fig, axs = plt.subplots(5, 2, figsize=(10, 8))\n",
        "\n",
        "    plt.suptitle(\"Recommended Items based on your selection\", fontsize=16, y=1.03)\n",
        "\n",
        "    selected_img = mpimg.imread(selected_img_path)\n",
        "    axs[0, 0].imshow(selected_img)\n",
        "    axs[0, 0].set_title(\"Item selected\")\n",
        "    axs[0, 0].axis('off')\n",
        "\n",
        "    num_neighbors = min(len(nearest_neighbor_paths), 10)\n",
        "\n",
        "    for i, ax in enumerate(axs[1:].flatten(), 1):\n",
        "        if i <= num_neighbors:\n",
        "            neighbor_path = nearest_neighbor_paths[i - 1]\n",
        "            img = mpimg.imread(neighbor_path)\n",
        "            ax.imshow(img)\n",
        "            ax.set_title(\"Recommended Item\")\n",
        "            ax.axis('off')\n",
        "\n",
        "    for i in range(5):\n",
        "        axs[i, 0].axis('off')\n",
        "        axs[i, 1].axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucqhOqoWws_Z"
      },
      "outputs": [],
      "source": [
        "# Caminho dos dados de treino e validação\n",
        "root_dir = 'complete-the-look-dataset/datasets/raw_train.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAVVUOXzwh8W"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(root_dir + '/train_df.csv')\n",
        "val_df = pd.read_csv(root_dir + '/val_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXRKixg3wh3a"
      },
      "outputs": [],
      "source": [
        "train_df['filename'] = root_dir + '/train_dataset/' + train_df['filename']\n",
        "val_df['filename'] = root_dir + '/validation_dataset/' + val_df['filename']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5gcqyakwh1F"
      },
      "outputs": [],
      "source": [
        "# Mapeamento de categorias de itens para IDs numéricos\n",
        "label_name_to_id = {\n",
        "    'Pants': 0,\n",
        "    'Handbags': 1,\n",
        "    'Shirts': 2,\n",
        "    'Shoes': 3,\n",
        "    'Scarves': 4,\n",
        "    'Jewelry': 5,\n",
        "    'Skirts': 6,\n",
        "    'Coats': 7,\n",
        "    'Hats': 8,\n",
        "    'Dresses': 9,\n",
        "    'Shorts': 10,\n",
        "    'Watches': 11,\n",
        "    'Sunglasses': 12,\n",
        "    'Jumpsuits': 13,\n",
        "    'Socks': 14,\n",
        "    'Rings': 15,\n",
        "    'Belts': 16,\n",
        "    'Gloves': 17,\n",
        "    'Swimwear': 18,\n",
        "    'Stockings': 19,\n",
        "    'Neckties': 20\n",
        "}\n",
        "\n",
        "train_df['label_id'] = train_df['category'].map(label_name_to_id).copy()\n",
        "val_df['label_id'] = val_df['category'].map(label_name_to_id).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9Za4PBjxQIy"
      },
      "outputs": [],
      "source": [
        "# Classe para preparar o dataset de moda com transformações necessárias\n",
        "class FashionDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.transformations = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "    def __getitem__(self, key):\n",
        "        if isinstance(key, slice):\n",
        "            raise NotImplementedError('slicing is not supported')\n",
        "        row = self.df.iloc[key]\n",
        "        try:\n",
        "          image = Image.open(row['filename']).convert(\"RGB\").resize((128, 128))\n",
        "        except OSError as e:\n",
        "          print(f\"Error: {e}\")\n",
        "        image = self.transformations(image)\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79EMl3_DxQAM"
      },
      "outputs": [],
      "source": [
        "# Criação dos conjuntos de treino e validação\n",
        "train_set = FashionDataset(train_df)\n",
        "val_set = FashionDataset(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJo6HFPexP9m"
      },
      "outputs": [],
      "source": [
        "# Definição do modelo de autoencoder\n",
        "class FeaturizerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeaturizerModel, self).__init__()\n",
        "        self.encoder = nn.Sequential(# in- (BS,3,128, 128)\n",
        "\n",
        "            nn.Conv2d(in_channels=3,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=64,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=2,\n",
        "                      padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=128,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128,\n",
        "                      out_channels=256,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=2,\n",
        "                      padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, stride=2), #13\n",
        "\n",
        "            nn.Conv2d(in_channels=256, #14\n",
        "                      out_channels=512,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(True), # 15\n",
        "            nn.Conv2d(in_channels=512, #16\n",
        "                      out_channels=512,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.Conv2d(in_channels=512,\n",
        "                      out_channels=512,\n",
        "                      kernel_size=(3, 3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(True),            # 17\n",
        "            nn.MaxPool2d(2, stride=2) # 18\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=512, #20\n",
        "                               out_channels=512,\n",
        "                               kernel_size=(3,3),\n",
        "                               stride=1,\n",
        "                              padding=1),\n",
        "            nn.ReLU(True), #22\n",
        "            nn.ConvTranspose2d(in_channels=512, #23\n",
        "                               out_channels=256,\n",
        "                               kernel_size=(3, 3),\n",
        "                               stride=2,\n",
        "                               padding=0),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=256, #24\n",
        "                               out_channels=128,\n",
        "                               kernel_size=(3,3),\n",
        "                               stride=2,\n",
        "                               padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=128,\n",
        "                               out_channels=64,\n",
        "                               kernel_size=(3,3),\n",
        "                               stride=2,\n",
        "                               padding=1),\n",
        "            nn.ConvTranspose2d(in_channels=64,\n",
        "                               out_channels=64,\n",
        "                               kernel_size=(3,3),\n",
        "                               stride=2,\n",
        "                               padding=1),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(in_channels=64,\n",
        "                               out_channels=32,\n",
        "                               kernel_size=(3,3),\n",
        "                               stride=2,\n",
        "                               padding=1),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=32,\n",
        "                               out_channels=32,\n",
        "                               kernel_size=(3,3),\n",
        "                               stride=2,\n",
        "                               padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(in_channels=32,\n",
        "                               out_channels=3,\n",
        "                               kernel_size=(4,4),\n",
        "                               stride=2,\n",
        "                               padding=2),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yALJxxnvxP6_"
      },
      "outputs": [],
      "source": [
        "# Criação do modelo e envio para o dispositivo\n",
        "featurizer_model = FeaturizerModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D49gXtQmxXPf"
      },
      "outputs": [],
      "source": [
        "# Função para carregar checkpoints do modelo\n",
        "def load_checkpoint(checkpoint_fpath, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    return model, optimizer, checkpoint['epoch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR3HKuK0xXFV"
      },
      "outputs": [],
      "source": [
        "# Função para salvar checkpoints do modelo\n",
        "def save_checkpoint(state, filename):\n",
        "    print(\"=> new best achieved, chechpoint saved\")\n",
        "    torch.save(state, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Owif_JxxXA5"
      },
      "outputs": [],
      "source": [
        "# Função de treino do modelo com validação\n",
        "def train_model(model, criterion, optimizer, num_epochs):\n",
        "  since = time.time()\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_loss = np.inf\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "    print('-' * 10)\n",
        "\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "\n",
        "\n",
        "      for idx, inputs in enumerate(Bar(dataloaders[phase])):\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, inputs)\n",
        "\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      epoch_loss = running_loss / dataset_sizes[phase]\n",
        "      print(' {} Loss: {:.4f}'.format(phase, epoch_loss))\n",
        "\n",
        "      if phase == 'val' and epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        save_checkpoint(state={\n",
        "            'epoch': epoch,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_loss': best_loss,\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "        }, filename='ckpt_epoch_{}.pt'.format(epoch))\n",
        "\n",
        "    print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "      time_elapsed // 60, time_elapsed % 60\n",
        "  ))\n",
        "  print('Best val Loss: {:4f}'.format(best_loss))\n",
        "\n",
        "\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, optimizer, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl7S5gKCxW8v"
      },
      "outputs": [],
      "source": [
        "# Configurações de hiperparâmetros\n",
        "EPOCHS = 40\n",
        "NUM_BATCHES = 128\n",
        "RETRAIN = False\n",
        "\n",
        "dataloaders = {'train': DataLoader(train_set, batch_size=NUM_BATCHES, num_workers=2),\n",
        "               'val': DataLoader(val_set, batch_size=NUM_BATCHES, num_workers=2)}\n",
        "\n",
        "dataset_sizes = {'train': len(train_set), 'val': len(val_set)}\n",
        "\n",
        "model = featurizer_model\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5yD6Q1uxW3R"
      },
      "outputs": [],
      "source": [
        "# Condicional para carregar o modelo\n",
        "if RETRAIN == True:\n",
        "    model, optimizer, state_epoch = load_checkpoint('resnet18-featurizer.pt', model, optimizer)\n",
        "    print('Checkpoint Loaded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLilPAqwxWzo"
      },
      "outputs": [],
      "source": [
        "# Função para treinar o modelo\n",
        "model, optimizer, loss = train_model(model=model,\n",
        "                                     criterion=criterion,\n",
        "                                     optimizer=optimizer,\n",
        "                                     num_epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nmJzpJ0xWwg"
      },
      "outputs": [],
      "source": [
        "# Salvando o estado atual do modelo\n",
        "torch.save({\n",
        "    'epochs': EPOCHS,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss\n",
        "}, 'featurizer-model-1.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gn2QOcVxWuJ"
      },
      "outputs": [],
      "source": [
        "# Definindo as transformações de imagem para pré-processamento\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZeffLUpxWrE"
      },
      "outputs": [],
      "source": [
        "# Carrega o modelo\n",
        "model = featurizer_model.to(device)\n",
        "model.load_state_dict(torch.load('featurizer-model-1.pt', map_location=device)['model_state_dict'], strict=False)\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}